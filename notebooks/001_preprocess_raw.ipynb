{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9f2a37f",
   "metadata": {},
   "source": [
    "# 001_preprocess_raw.ipynb\n",
    "Notebook para padronizar datasets do UCI em CSV, com alvo numérico e normalização.\n",
    "\n",
    "Este notebook:\n",
    "1. Lê os arquivos brutos em `data/raw/` para **banknote_authentication**, **breast_cancer (WDBC)** e **sonar**.\n",
    "2. Converte o alvo categórico para numérico.\n",
    "3. Normaliza os atributos (MinMaxScaler ou StandardScaler).\n",
    "4. Salva CSVs padronizados em `data/processed/<dataset>/`:\n",
    "   - `dataset_clean.csv` com valores originais e `target` numérico\n",
    "   - `dataset_normalized.csv` com atributos normalizados e `target` numérico\n",
    "5. Salva um `label_map.json` com o mapeamento do alvo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b89a8c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE: c:\\Users\\hopper\\Documents\\Mestrado\\Quantica\\qml-ga-project\n",
      "RAW : c:\\Users\\hopper\\Documents\\Mestrado\\Quantica\\qml-ga-project\\data\\raw exists? True\n",
      "PROC: c:\\Users\\hopper\\Documents\\Mestrado\\Quantica\\qml-ga-project\\data\\processed exists? True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "def find_repo_root(start=None):\n",
    "    \"\"\"Sobe diretórios até achar um marcador do projeto (pyproject.toml, .git ou configs/).\"\"\"\n",
    "    cur = os.path.abspath(start or os.getcwd())\n",
    "    markers = {\"pyproject.toml\", \".git\", \"configs\"}\n",
    "    while True:\n",
    "        if any(os.path.exists(os.path.join(cur, m)) for m in markers):\n",
    "            return cur\n",
    "        parent = os.path.dirname(cur)\n",
    "        if parent == cur:  # chegou na raiz do drive\n",
    "            # fallback: sobe um nível (útil se estiver em notebooks/)\n",
    "            return os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "        cur = parent\n",
    "\n",
    "BASE = find_repo_root()\n",
    "RAW  = os.path.join(BASE, \"data\", \"raw\")\n",
    "PROC = os.path.join(BASE, \"data\", \"processed\")\n",
    "\n",
    "SCALER_KIND = \"minmax\"  # troque para \"standard\" se preferir\n",
    "\n",
    "# Garante que as pastas de saída existam\n",
    "os.makedirs(PROC, exist_ok=True)\n",
    "\n",
    "# Opcional: alinhar o CWD à raiz do projeto para evitar surpresas\n",
    "os.chdir(BASE)\n",
    "\n",
    "print(\"BASE:\", BASE)\n",
    "print(\"RAW :\", RAW, \"exists?\", os.path.exists(RAW))\n",
    "print(\"PROC:\", PROC, \"exists?\", os.path.exists(PROC))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03fe9304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize_features(df: pd.DataFrame, target_col: str, kind: str = \"minmax\") -> pd.DataFrame:\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col].copy()\n",
    "    scaler = StandardScaler() if kind == \"standard\" else MinMaxScaler()\n",
    "    Xs = pd.DataFrame(scaler.fit_transform(X), columns=X.columns, index=X.index)\n",
    "    out = Xs.assign(**{target_col: y.values})\n",
    "    return out\n",
    "\n",
    "def _save_outputs(dataset_name: str, df_clean: pd.DataFrame, df_norm: pd.DataFrame, label_map: dict):\n",
    "    out_dir = os.path.join(PROC, dataset_name)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    df_clean.to_csv(os.path.join(out_dir, \"dataset_clean.csv\"), index=False)\n",
    "    df_norm.to_csv(os.path.join(out_dir, \"dataset_normalized.csv\"), index=False)\n",
    "    with open(os.path.join(out_dir, \"label_map.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(label_map, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"[OK] {dataset_name}: {len(df_clean)} linhas | salvo em {out_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee70243",
   "metadata": {},
   "source": [
    "## Banknote Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2e642dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] banknote_authentication: 1372 linhas | salvo em c:\\Users\\hopper\\Documents\\Mestrado\\Quantica\\qml-ga-project\\data\\processed\\banknote_authentication\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        f1      f2      f3       f4  target\n",
       "0  3.62160  8.6661 -2.8073 -0.44699       0\n",
       "1  4.54590  8.1674 -2.4586 -1.46210       0\n",
       "2  3.86600 -2.6383  1.9242  0.10645       0\n",
       "3  3.45660  9.5228 -4.0112 -3.59440       0\n",
       "4  0.32924 -4.4552  4.5718 -0.98880       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_banknote():\n",
    "    path = os.path.join(RAW, \"banknote_authentication\", \"data_banknote_authentication.txt\")\n",
    "    df = pd.read_csv(path, header=None)\n",
    "    cols = [f\"f{i}\" for i in range(1, df.shape[1])] + [\"target\"]\n",
    "    df.columns = cols\n",
    "    # Alvo já é 0 e 1 no arquivo original\n",
    "    label_map = {\"neg\": 0, \"pos\": 1, \"from_file\": \"already_numeric_0_1\"}\n",
    "    return df, label_map\n",
    "\n",
    "df_bank, map_bank = load_banknote()\n",
    "df_bank_norm = _normalize_features(df_bank, \"target\", SCALER_KIND)\n",
    "_ = _save_outputs(\"banknote_authentication\", df_bank, df_bank_norm, map_bank)\n",
    "df_bank.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d14f9c2",
   "metadata": {},
   "source": [
    "## Breast Cancer Wisconsin (Diagnostic) — WDBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e08c97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] breast_cancer_wdbc: 569 linhas | salvo em c:\\Users\\hopper\\Documents\\Mestrado\\Quantica\\qml-ga-project\\data\\processed\\breast_cancer_wdbc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>f28</th>\n",
       "      <th>f29</th>\n",
       "      <th>f30</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      f1     f2      f3      f4       f5       f6      f7       f8      f9  \\\n",
       "0  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001  0.14710  0.2419   \n",
       "1  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869  0.07017  0.1812   \n",
       "2  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974  0.12790  0.2069   \n",
       "3  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414  0.10520  0.2597   \n",
       "4  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980  0.10430  0.1809   \n",
       "\n",
       "       f10  ...    f22     f23     f24     f25     f26     f27     f28  \\\n",
       "0  0.07871  ...  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
       "1  0.05667  ...  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "2  0.05999  ...  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "3  0.09744  ...  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "4  0.05883  ...  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "\n",
       "      f29      f30  target  \n",
       "0  0.4601  0.11890       1  \n",
       "1  0.2750  0.08902       1  \n",
       "2  0.3613  0.08758       1  \n",
       "3  0.6638  0.17300       1  \n",
       "4  0.2364  0.07678       1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_wdbc():\n",
    "    path = os.path.join(RAW, \"breast_cancer\", \"wdbc.data\")\n",
    "    df = pd.read_csv(path, header=None)\n",
    "    cols = [\"id\", \"diagnosis\"] + [f\"f{i}\" for i in range(1, 31)]\n",
    "    if df.shape[1] != len(cols):\n",
    "        raise ValueError(f\"Esperado 32 colunas, encontrado {df.shape[1]}\")\n",
    "    df.columns = cols\n",
    "    label_map = {\"B\": 0, \"M\": 1}\n",
    "    df[\"target\"] = df[\"diagnosis\"].map(label_map).astype(int)\n",
    "    df = df.drop(columns=[\"id\", \"diagnosis\"])\n",
    "    return df, label_map\n",
    "\n",
    "df_wdbc, map_wdbc = load_wdbc()\n",
    "df_wdbc_norm = _normalize_features(df_wdbc, \"target\", SCALER_KIND)\n",
    "_ = _save_outputs(\"breast_cancer_wdbc\", df_wdbc, df_wdbc_norm, map_wdbc)\n",
    "df_wdbc.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07833f76",
   "metadata": {},
   "source": [
    "## Sonar — Mines vs Rocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62ab9785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] sonar: 208 linhas | salvo em c:\\Users\\hopper\\Documents\\Mestrado\\Quantica\\qml-ga-project\\data\\processed\\sonar\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f52</th>\n",
       "      <th>f53</th>\n",
       "      <th>f54</th>\n",
       "      <th>f55</th>\n",
       "      <th>f56</th>\n",
       "      <th>f57</th>\n",
       "      <th>f58</th>\n",
       "      <th>f59</th>\n",
       "      <th>f60</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       f1      f2      f3      f4      f5      f6      f7      f8      f9  \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "      f10  ...     f52     f53     f54     f55     f56     f57     f58  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "      f59     f60  target  \n",
       "0  0.0090  0.0032       0  \n",
       "1  0.0052  0.0044       0  \n",
       "2  0.0095  0.0078       0  \n",
       "3  0.0040  0.0117       0  \n",
       "4  0.0107  0.0094       0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_sonar():\n",
    "    path = os.path.join(RAW, \"sonar\", \"sonar.all-data\")\n",
    "    df = pd.read_csv(path, header=None)\n",
    "    if df.shape[1] != 61:\n",
    "        raise ValueError(f\"Esperado 61 colunas 60 features + 1 alvo, encontrado {df.shape[1]}\")\n",
    "    cols = [f\"f{i}\" for i in range(1, 61)] + [\"label\"]\n",
    "    df.columns = cols\n",
    "    label_map = {\"R\": 0, \"M\": 1}\n",
    "    df[\"target\"] = df[\"label\"].map(label_map).astype(int)\n",
    "    df = df.drop(columns=[\"label\"])\n",
    "    return df, label_map\n",
    "\n",
    "df_sonar, map_sonar = load_sonar()\n",
    "df_sonar_norm = _normalize_features(df_sonar, \"target\", SCALER_KIND)\n",
    "_ = _save_outputs(\"sonar\", df_sonar, df_sonar_norm, map_sonar)\n",
    "df_sonar.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c09fdea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'banknote_authentication': {'clean_path': 'c:\\\\Users\\\\hopper\\\\Documents\\\\Mestrado\\\\Quantica\\\\qml-ga-project\\\\data\\\\processed\\\\banknote_authentication\\\\dataset_clean.csv',\n",
       "  'normalized_path': 'c:\\\\Users\\\\hopper\\\\Documents\\\\Mestrado\\\\Quantica\\\\qml-ga-project\\\\data\\\\processed\\\\banknote_authentication\\\\dataset_normalized.csv'},\n",
       " 'breast_cancer_wdbc': {'clean_path': 'c:\\\\Users\\\\hopper\\\\Documents\\\\Mestrado\\\\Quantica\\\\qml-ga-project\\\\data\\\\processed\\\\breast_cancer_wdbc\\\\dataset_clean.csv',\n",
       "  'normalized_path': 'c:\\\\Users\\\\hopper\\\\Documents\\\\Mestrado\\\\Quantica\\\\qml-ga-project\\\\data\\\\processed\\\\breast_cancer_wdbc\\\\dataset_normalized.csv'},\n",
       " 'sonar': {'clean_path': 'c:\\\\Users\\\\hopper\\\\Documents\\\\Mestrado\\\\Quantica\\\\qml-ga-project\\\\data\\\\processed\\\\sonar\\\\dataset_clean.csv',\n",
       "  'normalized_path': 'c:\\\\Users\\\\hopper\\\\Documents\\\\Mestrado\\\\Quantica\\\\qml-ga-project\\\\data\\\\processed\\\\sonar\\\\dataset_normalized.csv'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = {\n",
    "    \"banknote_authentication\": {\n",
    "        \"clean_path\": os.path.abspath(os.path.join(PROC, \"banknote_authentication\", \"dataset_clean.csv\")),\n",
    "        \"normalized_path\": os.path.abspath(os.path.join(PROC, \"banknote_authentication\", \"dataset_normalized.csv\")),\n",
    "    },\n",
    "    \"breast_cancer_wdbc\": {\n",
    "        \"clean_path\": os.path.abspath(os.path.join(PROC, \"breast_cancer_wdbc\", \"dataset_clean.csv\")),\n",
    "        \"normalized_path\": os.path.abspath(os.path.join(PROC, \"breast_cancer_wdbc\", \"dataset_normalized.csv\")),\n",
    "    },\n",
    "    \"sonar\": {\n",
    "        \"clean_path\": os.path.abspath(os.path.join(PROC, \"sonar\", \"dataset_clean.csv\")),\n",
    "        \"normalized_path\": os.path.abspath(os.path.join(PROC, \"sonar\", \"dataset_normalized.csv\")),\n",
    "    },\n",
    "}\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d524f4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== banknote_authentication ===\n",
      "Distribuição de classes (clean):\n",
      "target\n",
      "0    0.555394\n",
      "1    0.444606\n",
      "Name: proportion, dtype: float64\n",
      "Distribuição de classes (normalized):\n",
      "target\n",
      "0    0.555394\n",
      "1    0.444606\n",
      "Name: proportion, dtype: float64\n",
      "Clean  mean/std (primeiras 3 colunas): [0.434, 1.922, 1.398] [2.843, 5.869, 4.31]\n",
      "Normed mean/std (primeiras 3 colunas): [0.539, 0.587, 0.288] [0.205, 0.22, 0.186]\n",
      "\n",
      "=== breast_cancer_wdbc ===\n",
      "Distribuição de classes (clean):\n",
      "target\n",
      "0    0.627417\n",
      "1    0.372583\n",
      "Name: proportion, dtype: float64\n",
      "Distribuição de classes (normalized):\n",
      "target\n",
      "0    0.627417\n",
      "1    0.372583\n",
      "Name: proportion, dtype: float64\n",
      "Clean  mean/std (primeiras 3 colunas): [14.127, 19.29, 91.969] [3.524, 4.301, 24.299]\n",
      "Normed mean/std (primeiras 3 colunas): [0.338, 0.324, 0.333] [0.167, 0.145, 0.168]\n",
      "\n",
      "=== sonar ===\n",
      "Distribuição de classes (clean):\n",
      "target\n",
      "0    0.466346\n",
      "1    0.533654\n",
      "Name: proportion, dtype: float64\n",
      "Distribuição de classes (normalized):\n",
      "target\n",
      "0    0.466346\n",
      "1    0.533654\n",
      "Name: proportion, dtype: float64\n",
      "Clean  mean/std (primeiras 3 colunas): [0.029, 0.038, 0.044] [0.023, 0.033, 0.038]\n",
      "Normed mean/std (primeiras 3 colunas): [0.204, 0.162, 0.139] [0.17, 0.141, 0.126]\n",
      "\n",
      "[OK] Sanity checks concluídos.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sanity_report(name, df_clean, df_norm, target=\"target\"):\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    # distribuição de classes\n",
    "    vc_clean = df_clean[target].value_counts(normalize=True).sort_index()\n",
    "    vc_norm  = df_norm[target].value_counts(normalize=True).sort_index()\n",
    "    print(\"Distribuição de classes (clean):\")\n",
    "    print(vc_clean)\n",
    "    print(\"Distribuição de classes (normalized):\")\n",
    "    print(vc_norm)\n",
    "\n",
    "    # checar que o target é idêntico\n",
    "    assert np.array_equal(df_clean[target].values, df_norm[target].values), \"target mudou após normalização\"\n",
    "\n",
    "    # checar estatísticas de features\n",
    "    Xc = df_clean.drop(columns=[target])\n",
    "    Xn = df_norm.drop(columns=[target])\n",
    "    print(\"Clean  mean/std (primeiras 3 colunas):\", Xc.iloc[:, :3].mean().round(3).tolist(), Xc.iloc[:, :3].std().round(3).tolist())\n",
    "    print(\"Normed mean/std (primeiras 3 colunas):\", Xn.iloc[:, :3].mean().round(3).tolist(), Xn.iloc[:, :3].std().round(3).tolist())\n",
    "\n",
    "sanity_report(\"banknote_authentication\", df_bank, df_bank_norm)\n",
    "sanity_report(\"breast_cancer_wdbc\", df_wdbc, df_wdbc_norm)\n",
    "sanity_report(\"sonar\", df_sonar, df_sonar_norm)\n",
    "print(\"\\n[OK] Sanity checks concluídos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce524fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] banknote_authentication: 10 folds estratificados salvos em c:\\Users\\hopper\\Documents\\Mestrado\\Quantica\\qml-ga-project\\data\\splits\\banknote_authentication\n",
      "[OK] breast_cancer_wdbc: 10 folds estratificados salvos em c:\\Users\\hopper\\Documents\\Mestrado\\Quantica\\qml-ga-project\\data\\splits\\breast_cancer_wdbc\n",
      "[OK] sonar: 10 folds estratificados salvos em c:\\Users\\hopper\\Documents\\Mestrado\\Quantica\\qml-ga-project\\data\\splits\\sonar\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "SPLITS_DIR = os.path.join(BASE, \"data\", \"splits\")\n",
    "os.makedirs(SPLITS_DIR, exist_ok=True)\n",
    "\n",
    "def export_stratified_folds(name, df_clean, target=\"target\", n_splits=10, seed=42):\n",
    "    out_dir = os.path.join(SPLITS_DIR, name)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    y = df_clean[target].values\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    for i, (tr, te) in enumerate(skf.split(df_clean, y), start=1):\n",
    "        pd.DataFrame({\"idx\": tr}).to_csv(os.path.join(out_dir, f\"fold_{i:02d}_train.csv\"), index=False)\n",
    "        pd.DataFrame({\"idx\": te}).to_csv(os.path.join(out_dir, f\"fold_{i:02d}_test.csv\"), index=False)\n",
    "    print(f\"[OK] {name}: {n_splits} folds estratificados salvos em {out_dir}\")\n",
    "\n",
    "export_stratified_folds(\"banknote_authentication\", df_bank)\n",
    "export_stratified_folds(\"breast_cancer_wdbc\", df_wdbc)\n",
    "export_stratified_folds(\"sonar\", df_sonar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2d31aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] summary salvo em c:\\Users\\hopper\\Documents\\Mestrado\\Quantica\\qml-ga-project\\data\\processed\\_summary.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'banknote_authentication': {'n_rows': 1372,\n",
       "  'n_features': 4,\n",
       "  'n_classes': 2,\n",
       "  'clean_csv': 'c:\\\\Users\\\\hopper\\\\Documents\\\\Mestrado\\\\Quantica\\\\qml-ga-project\\\\data\\\\processed\\\\banknote_authentication\\\\dataset_clean.csv',\n",
       "  'normalized_csv': 'c:\\\\Users\\\\hopper\\\\Documents\\\\Mestrado\\\\Quantica\\\\qml-ga-project\\\\data\\\\processed\\\\banknote_authentication\\\\dataset_normalized.csv'},\n",
       " 'breast_cancer_wdbc': {'n_rows': 569,\n",
       "  'n_features': 30,\n",
       "  'n_classes': 2,\n",
       "  'clean_csv': 'c:\\\\Users\\\\hopper\\\\Documents\\\\Mestrado\\\\Quantica\\\\qml-ga-project\\\\data\\\\processed\\\\breast_cancer_wdbc\\\\dataset_clean.csv',\n",
       "  'normalized_csv': 'c:\\\\Users\\\\hopper\\\\Documents\\\\Mestrado\\\\Quantica\\\\qml-ga-project\\\\data\\\\processed\\\\breast_cancer_wdbc\\\\dataset_normalized.csv'},\n",
       " 'sonar': {'n_rows': 208,\n",
       "  'n_features': 60,\n",
       "  'n_classes': 2,\n",
       "  'clean_csv': 'c:\\\\Users\\\\hopper\\\\Documents\\\\Mestrado\\\\Quantica\\\\qml-ga-project\\\\data\\\\processed\\\\sonar\\\\dataset_clean.csv',\n",
       "  'normalized_csv': 'c:\\\\Users\\\\hopper\\\\Documents\\\\Mestrado\\\\Quantica\\\\qml-ga-project\\\\data\\\\processed\\\\sonar\\\\dataset_normalized.csv'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "meta = {\n",
    "    \"banknote_authentication\": {\n",
    "        \"n_rows\": len(df_bank),\n",
    "        \"n_features\": df_bank.shape[1] - 1,\n",
    "        \"n_classes\": int(df_bank[\"target\"].nunique()),\n",
    "        \"clean_csv\": summary[\"banknote_authentication\"][\"clean_path\"],\n",
    "        \"normalized_csv\": summary[\"banknote_authentication\"][\"normalized_path\"],\n",
    "    },\n",
    "    \"breast_cancer_wdbc\": {\n",
    "        \"n_rows\": len(df_wdbc),\n",
    "        \"n_features\": df_wdbc.shape[1] - 1,\n",
    "        \"n_classes\": int(df_wdbc[\"target\"].nunique()),\n",
    "        \"clean_csv\": summary[\"breast_cancer_wdbc\"][\"clean_path\"],\n",
    "        \"normalized_csv\": summary[\"breast_cancer_wdbc\"][\"normalized_path\"],\n",
    "    },\n",
    "    \"sonar\": {\n",
    "        \"n_rows\": len(df_sonar),\n",
    "        \"n_features\": df_sonar.shape[1] - 1,\n",
    "        \"n_classes\": int(df_sonar[\"target\"].nunique()),\n",
    "        \"clean_csv\": summary[\"sonar\"][\"clean_path\"],\n",
    "        \"normalized_csv\": summary[\"sonar\"][\"normalized_path\"],\n",
    "    },\n",
    "}\n",
    "out_meta = os.path.join(PROC, \"_summary.json\")\n",
    "with open(out_meta, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(meta, f, ensure_ascii=False, indent=2)\n",
    "print(f\"[OK] summary salvo em {out_meta}\")\n",
    "meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e066e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qml-ga-project-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
